{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f0dcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/nlaurent/anaconda3/envs/wcs-units/lib/python313.zip', '/home/nlaurent/anaconda3/envs/wcs-units/lib/python3.13', '/home/nlaurent/anaconda3/envs/wcs-units/lib/python3.13/lib-dynload', '', '/home/nlaurent/.local/lib/python3.13/site-packages', '/home/nlaurent/anaconda3/envs/wcs-units/lib/python3.13/site-packages', '../src']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')  # Adds the parent directory to the Python path\n",
    "print(sys.path)\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from dfreproject import calculate_reprojection\n",
    "from sunpy.data.sample import AIA_193_JUN2012, STEREO_A_195_JUN2012\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from astropy.io.fits import PrimaryHDU\n",
    "from dfreproject import TensorHDU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443a0157",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def downscale_and_update_fits(source_hdu, target_hdu, target_wcs, downscale_size):\n",
    "\n",
    "    # Downscale both images to downscale_size x downscale_size using torch (bilinear interpolation)\n",
    "    def downscale_to_size(img, size):\n",
    "        arr = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        arr_down = torch.nn.functional.interpolate(arr, size=(size, size), mode='bilinear', align_corners=False)\n",
    "        return arr_down.squeeze().numpy()\n",
    "\n",
    "    source_down = downscale_to_size(source_hdu.data, downscale_size)\n",
    "    target_down = downscale_to_size(target_hdu.data, downscale_size)\n",
    "\n",
    "    # Update FITS headers for new shape\n",
    "    source_header = source_hdu.header.copy()\n",
    "    target_header = target_hdu.header.copy()\n",
    "    source_header['NAXIS1'] = downscale_size\n",
    "    source_header['NAXIS2'] = downscale_size\n",
    "    target_header['NAXIS1'] = downscale_size\n",
    "    target_header['NAXIS2'] = downscale_size\n",
    "\n",
    "    # Optionally update CDELT1/2 to preserve FOV (if desired)\n",
    "    if 'CDELT1' in source_header and 'NAXIS1' in source_hdu.header:\n",
    "        scale = source_hdu.header['NAXIS1'] / downscale_size\n",
    "        source_header['CDELT1'] = source_hdu.header['CDELT1'] * scale\n",
    "        source_header['CDELT2'] = source_hdu.header['CDELT2'] * scale\n",
    "    if 'CDELT1' in target_header and 'NAXIS1' in target_hdu.header:\n",
    "        scale = target_hdu.header['NAXIS1'] / downscale_size\n",
    "        target_header['CDELT1'] = target_hdu.header['CDELT1'] * scale\n",
    "        target_header['CDELT2'] = target_hdu.header['CDELT2'] * scale\n",
    "    # Update CRPIX1/2 to match new image center after resizing\n",
    "    if 'CRPIX1' in source_header and 'NAXIS1' in source_hdu.header:\n",
    "        scale = source_hdu.header['NAXIS1'] / downscale_size\n",
    "        source_header['CRPIX1'] = source_hdu.header['CRPIX1'] / scale\n",
    "        source_header['CRPIX2'] = source_hdu.header['CRPIX2'] / scale\n",
    "    if 'CRPIX1' in target_header and 'NAXIS1' in target_hdu.header:\n",
    "        scale = target_hdu.header['NAXIS1'] / downscale_size\n",
    "        target_header['CRPIX1'] = target_hdu.header['CRPIX1'] / scale\n",
    "        target_header['CRPIX2'] = target_hdu.header['CRPIX2'] / scale\n",
    "\n",
    "    new_source_hdu = TensorHDU(torch.tensor(source_down, dtype=torch.float64, requires_grad=True, device=torch.device(\"cpu\")), source_header)\n",
    "    new_target_hdu = PrimaryHDU(target_down, header=target_header)\n",
    "    new_target_wcs = WCS(target_header)\n",
    "\n",
    "    return new_source_hdu, new_target_hdu, new_target_wcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c33a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: Invalid 'BLANK' keyword in header.  The 'BLANK' keyword is only applicable to integer data, and will be ignored in this HDU. [astropy.io.fits.hdu.image]\n",
      "WARNING: FITSFixedWarning: CROTA = -2.53888423492 / \n",
      "keyword looks very much like CROTAn but isn't. [astropy.wcs.wcs]\n",
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to 56079.003829 from DATE-OBS.\n",
      "Set MJD-AVG to 56079.003875 from DATE-AVG.\n",
      "Set MJD-END to 56079.003922 from DATE-END'. [astropy.wcs.wcs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'astropy.io.fits.hdu.image.PrimaryHDU'>\n",
      "Converted numpy array to torch tensor with requires_grad=True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to 56079.000091 from DATE-OBS'. [astropy.wcs.wcs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 2048])\n",
      "True\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PrimaryHDU' object has no attribute 'tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(reprojected.requires_grad)  \u001b[38;5;66;03m# Should be True if requires_grad=True was passed\u001b[39;00m\n\u001b[32m     33\u001b[39m reprojected.sum().backward()\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43msource_hdu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m.grad)\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Plot with a diverging colormap centered at zero for gradients\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'PrimaryHDU' object has no attribute 'tensor'"
     ]
    }
   ],
   "source": [
    "# Load source and target images\n",
    "source_hdu = fits.open(AIA_193_JUN2012)[1]\n",
    "target_hdu = fits.open(STEREO_A_195_JUN2012)[1]\n",
    "source_hdu = PrimaryHDU(source_hdu.data, header=source_hdu.header)\n",
    "\n",
    "source_hdu = (torch.tensor(source_hdu.data, requires_grad=True), source_hdu.header)\n",
    "\n",
    "source_hdu = TensorHDU(torch.tensor(source_hdu.data, requires_grad=True), source_hdu.header)\n",
    "alt_tensor = source_hdu.tensor \n",
    "alt_header = source_hdu.header\n",
    "target_hdu = PrimaryHDU(target_hdu.data, header=target_hdu.header)\n",
    "\n",
    "target_wcs = WCS(target_hdu.header)\n",
    "# Use the downscale_and_update_fits function defined above\n",
    "# downscale_size = 1024\n",
    "# source_hdu, target_hdu, target_wcs = downscale_and_update_fits(source_hdu, target_hdu, target_wcs, downscale_size=downscale_size)\n",
    "print(type(source_hdu))\n",
    "\n",
    "\n",
    "\n",
    "reprojected = calculate_reprojection(\n",
    "    source_hdus = source_hdu,\n",
    "    target_wcs=target_wcs,\n",
    "    shape_out=target_hdu.data.shape,\n",
    "    order='bilinear',\n",
    "    requires_grad=True,\n",
    ")\n",
    "\n",
    "print(reprojected.shape)  # Should match target_hdu.data.shape\n",
    "\n",
    "\n",
    "print(reprojected.requires_grad)  # Should be True if requires_grad=True was passed\n",
    "reprojected.sum().backward()\n",
    "print(source_hdu.tensor.grad)\n",
    "# Plot with a diverging colormap centered at zero for gradients\n",
    "import numpy as np\n",
    "\n",
    "grad = source_hdu.tensor.grad.cpu().numpy()\n",
    "# Use percentiles to avoid outlier-dominated color scaling\n",
    "vmax = np.nanpercentile(np.abs(grad), 99)\n",
    "if vmax == 0 or np.isnan(vmax):\n",
    "    vmax = 1e-8  # fallback to avoid division by zero\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "axes[0].imshow(source_hdu.data, cmap='magma')\n",
    "axes[0].set_title('Source (AIA)')\n",
    "axes[1].imshow(target_hdu.data, cmap='viridis')\n",
    "axes[1].set_title('Target (STEREO)')\n",
    "axes[2].imshow(reprojected.detach(), cmap='magma')\n",
    "axes[2].set_title('Reprojected (AIA to STEREO)')\n",
    "im = axes[3].imshow(grad, cmap='RdBu_r', vmin=-vmax, vmax=vmax)\n",
    "axes[3].set_title('Backward Output (Grad)')\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "fig.colorbar(im, ax=axes[3], fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wcs-units",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
